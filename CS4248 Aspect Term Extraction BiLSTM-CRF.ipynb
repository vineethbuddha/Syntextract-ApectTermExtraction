{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c9db93",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9420a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import math\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "import glob\n",
    "import spacy\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf241c",
   "metadata": {},
   "source": [
    "### Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1991987",
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding_feature = 'GLOVE' #Skipgram / GLOVE\n",
    "POS_feature = 'No' #No / Yes\n",
    "Dataset_domain = 'Laptops' #Laptops / Restaurants\n",
    "POS_hidden_dim = 128 #256 / 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6003ec",
   "metadata": {},
   "source": [
    "### Read in data and tagging IOB to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca193348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To extract the soup object and extract the relevant aspect terms from xml file\n",
    "def soup2dict(sentence_nodes):\n",
    "\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    for n in sentence_nodes:\n",
    "        i += 1\n",
    "        sentence = {}\n",
    "        aspect_term = []\n",
    "        sentence['id'] = i\n",
    "        sentence['text'] = n.find('text').string\n",
    "        if n.find('aspectTerms'):\n",
    "            for c in n.find('aspectTerms').contents:\n",
    "                if c.name == 'aspectTerm':\n",
    "                    if c['term'] not in aspect_term:\n",
    "                        aspect_term.append(c['term'])\n",
    "\n",
    "        sentence['aspect'] = aspect_term\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807622ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "def split2words(s_text):\n",
    "\n",
    "    s_text = re.sub('([.,!?()])', r' \\1 ', s_text) # match the punctuation characters and surround them by spaces,\n",
    "    s_text = re.sub('\\s{2,}', ' ', s_text)         # collapse multiple spaces to one space\n",
    "    words = s_text.lower().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b42939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to tag each words to IOB based on the aspect terms\n",
    "def tagging_IOB(s, aspects):\n",
    "\n",
    "    tags = ['O'] * len(s)\n",
    "    \n",
    "    #print(s)\n",
    "\n",
    "    for aspect in aspects:\n",
    "        aspect_tokens = split2words(aspect)\n",
    "        aspect_len = len(aspect_tokens)\n",
    "        len_counter = 0\n",
    "        pre_index = -math.inf\n",
    "        for word in s: \n",
    "            #print('word is', word)\n",
    "            if len_counter <aspect_len:\n",
    "                if word in aspect_tokens: \n",
    "                    len_counter += 1\n",
    "                    cur_index = s.index(word) \n",
    "                    if cur_index - pre_index == 1: # inside an aspect term\n",
    "                        tags[cur_index] = 'I'\n",
    "                    else:                       # beginning of an aspect term\n",
    "                        tags[cur_index] = 'B'\n",
    "                    pre_index = cur_index \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44346aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert into df format for saving the files\n",
    "def dict2df(sentences):\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    for s in sentences:\n",
    "        sentence = {}\n",
    "        sentence['Sentence #'] = s['id']\n",
    "        sentence['Word'] = split2words(s['text'])  # split text to words\n",
    "        s_length = len(sentence['Word']) # the length of sentence, used to generate tag\n",
    "        if len(s['aspect'])==0 or s['aspect'][0] == 'NULL': # tagging: if no aspect term\n",
    "            sentence['Tag'] = ['O'] * s_length\n",
    "        else:                                               # IOB format tag if aspect exist\n",
    "            aspect_terms = [x.lower() for x in s['aspect']]  \n",
    "            sentence['Tag'] = tagging_IOB(sentence['Word'], aspect_terms)\n",
    "\n",
    "        # convert each setence to dataframe \n",
    "        sentence_df = pd.DataFrame.from_dict(sentence)\n",
    "        data = data.append(sentence_df, ignore_index=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4d6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read the file and process the data based on above defined functions\n",
    "def read_data(file_path):\n",
    "    # convert xml raw data to soup\n",
    "    soup = None\n",
    "    with file_path.open(encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "    if soup is None:\n",
    "        raise Exception(\"Can't read xml file\")\n",
    "    sentence_nodes = soup.find_all(\"sentence\")\n",
    "\n",
    "    # convert soup object to a list of dictionaries and df\n",
    "    sentences = soup2dict(sentence_nodes)\n",
    "    data = dict2df(sentences)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4542c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and save the data\n",
    "if Dataset_domain == 'Restaurants': #Laptops\n",
    "    test_path = Path.cwd().joinpath('Restaurants_Test.xml')\n",
    "    train_path = Path.cwd().joinpath('Restaurants_Train.xml')\n",
    "else:\n",
    "    test_path = Path.cwd().joinpath('Laptops_Test.xml')\n",
    "    train_path = Path.cwd().joinpath('Laptops_Train.xml') \n",
    "    \n",
    "data_test = read_data(test_path)\n",
    "data_train = read_data(train_path)\n",
    "\n",
    "save_file = Path.cwd().joinpath('test.csv')\n",
    "data_test.to_csv(save_file, index=False)\n",
    "save_file = Path.cwd().joinpath('train.csv')\n",
    "data_train.to_csv(save_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab37737",
   "metadata": {},
   "source": [
    "### Process data for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e4517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read from previous saved file\n",
    "train_path = Path.cwd().joinpath('train.csv')\n",
    "test_path = Path.cwd().joinpath('test.csv')\n",
    "\n",
    "# Read data\n",
    "data_train = pd.read_csv(train_path)\n",
    "data_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ffdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vocab \n",
    "word_train = set(data_train['Word'].values)\n",
    "word_test = set(data_test['Word'].values)\n",
    "words = list(word_train.union(word_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f84281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'inside': 1,\n",
       " 'steer': 2,\n",
       " 'expecting': 3,\n",
       " 'reached': 4,\n",
       " 'handling': 5,\n",
       " 'avid': 6,\n",
       " 'overheats': 7,\n",
       " 'routed': 8,\n",
       " 'destroy': 9,\n",
       " '53%': 10,\n",
       " '\"wlan\"': 11,\n",
       " 'these': 12,\n",
       " \"arn't\": 13,\n",
       " 'laid': 14,\n",
       " 'plain': 15,\n",
       " 'serves': 16,\n",
       " 'fell': 17,\n",
       " 'rolls': 18,\n",
       " 'incident': 19,\n",
       " 'froze': 20,\n",
       " 'dark': 21,\n",
       " 'construction': 22,\n",
       " 'seconds': 23,\n",
       " 'velcro': 24,\n",
       " 'difficult': 25,\n",
       " 'impressive': 26,\n",
       " 'run-on': 27,\n",
       " 'lifestyle': 28,\n",
       " \"wouldn't\": 29,\n",
       " 'press': 30,\n",
       " 'manufacturer': 31,\n",
       " 'gradual': 32,\n",
       " 'dollar': 33,\n",
       " 'fingertips': 34,\n",
       " 'bell': 35,\n",
       " 'identified': 36,\n",
       " '3': 37,\n",
       " 'models': 38,\n",
       " 'moment': 39,\n",
       " 'coupons': 40,\n",
       " 'boot-up': 41,\n",
       " 'supposed': 42,\n",
       " 'receptacle': 43,\n",
       " 'talking': 44,\n",
       " 'laptop\"': 45,\n",
       " 'pop': 46,\n",
       " '$600': 47,\n",
       " 'touchpad': 48,\n",
       " 'good;': 49,\n",
       " 'anymore': 50,\n",
       " 'name': 51,\n",
       " 'cons': 52,\n",
       " 'drivers': 53,\n",
       " 'moved': 54,\n",
       " 'kinds': 55,\n",
       " 'ahold': 56,\n",
       " 'past;': 57,\n",
       " 'compared': 58,\n",
       " 'seeing': 59,\n",
       " 'restrictions': 60,\n",
       " 'responding': 61,\n",
       " 'another': 62,\n",
       " 'cell': 63,\n",
       " 'starters': 64,\n",
       " 'security': 65,\n",
       " '7hrs': 66,\n",
       " 'initially': 67,\n",
       " 'premium--delivered': 68,\n",
       " 'tops': 69,\n",
       " '150': 70,\n",
       " 'expenses': 71,\n",
       " 'make': 72,\n",
       " 'tools': 73,\n",
       " 'yes': 74,\n",
       " 'lot': 75,\n",
       " 'eeepc': 76,\n",
       " 'glossy': 77,\n",
       " 'meaning': 78,\n",
       " 'fatal': 79,\n",
       " 'alexandra': 80,\n",
       " '\"star': 81,\n",
       " 'restarts': 82,\n",
       " 'sort': 83,\n",
       " 'especially': 84,\n",
       " 'ordinarily': 85,\n",
       " '20': 86,\n",
       " 'tracking': 87,\n",
       " 'brother': 88,\n",
       " 'come': 89,\n",
       " 'imagine': 90,\n",
       " 'friends': 91,\n",
       " 'times': 92,\n",
       " 'popped': 93,\n",
       " 'guarentee': 94,\n",
       " 'lady': 95,\n",
       " 'allow': 96,\n",
       " 'than': 97,\n",
       " '$400': 98,\n",
       " 'bang': 99,\n",
       " 'projects': 100,\n",
       " 'accepted': 101,\n",
       " 'camp': 102,\n",
       " 'data': 103,\n",
       " 'bummer': 104,\n",
       " '$1899': 105,\n",
       " 'such': 106,\n",
       " 'retired': 107,\n",
       " 'limit': 108,\n",
       " 'fingerprints': 109,\n",
       " '500gb': 110,\n",
       " 'conference': 111,\n",
       " '\"bundled\"': 112,\n",
       " 'are': 113,\n",
       " 'simplest': 114,\n",
       " '-runs': 115,\n",
       " 'now': 116,\n",
       " 'recenlty': 117,\n",
       " 'upgrading': 118,\n",
       " 'unlikely': 119,\n",
       " 'couldnt': 120,\n",
       " '3\"': 121,\n",
       " 'narcissist': 122,\n",
       " 'toshie': 123,\n",
       " 'sexyy:d': 124,\n",
       " 'dvd': 125,\n",
       " \"'died'\": 126,\n",
       " 'provides': 127,\n",
       " 'convert': 128,\n",
       " 'over-sized': 129,\n",
       " 'myriad': 130,\n",
       " 'sweet': 131,\n",
       " 'anodized': 132,\n",
       " 'confident': 133,\n",
       " 'susceptible': 134,\n",
       " 'located': 135,\n",
       " 'paint': 136,\n",
       " 'music-management': 137,\n",
       " 'inept': 138,\n",
       " 'relieved': 139,\n",
       " 'admit': 140,\n",
       " 'perform': 141,\n",
       " 'upwards': 142,\n",
       " 'irreplaceable': 143,\n",
       " 'sucks': 144,\n",
       " \"90's\": 145,\n",
       " 'complained': 146,\n",
       " 'etc': 147,\n",
       " 'breeze': 148,\n",
       " 'ups': 149,\n",
       " 'bindings': 150,\n",
       " 'slip': 151,\n",
       " '-they': 152,\n",
       " 'husband': 153,\n",
       " 'managed': 154,\n",
       " 'wear': 155,\n",
       " 'art': 156,\n",
       " 'cover': 157,\n",
       " 'vids': 158,\n",
       " 'msft': 159,\n",
       " '4000': 160,\n",
       " '5hrs': 161,\n",
       " 'oline': 162,\n",
       " 'reach': 163,\n",
       " 'flaws': 164,\n",
       " 'basic': 165,\n",
       " 'liquid': 166,\n",
       " 'english': 167,\n",
       " 'polite': 168,\n",
       " 'bid': 169,\n",
       " \"wasn't\": 170,\n",
       " '4gb': 171,\n",
       " 'better-configured': 172,\n",
       " 'mbp': 173,\n",
       " 'compatible': 174,\n",
       " 'shipping': 175,\n",
       " 'literally': 176,\n",
       " 'holds': 177,\n",
       " 'foam': 178,\n",
       " 'encourage': 179,\n",
       " 'provider': 180,\n",
       " 'components': 181,\n",
       " 'qosmio': 182,\n",
       " 'restore': 183,\n",
       " 'lobe': 184,\n",
       " '\"mountain': 185,\n",
       " 'bars': 186,\n",
       " 'considering': 187,\n",
       " 'hurry': 188,\n",
       " 'science': 189,\n",
       " \"she's\": 190,\n",
       " 'currently': 191,\n",
       " 'carved': 192,\n",
       " 'compresses': 193,\n",
       " 'finding': 194,\n",
       " 'any;': 195,\n",
       " '5d': 196,\n",
       " 'straws;': 197,\n",
       " 'prominent': 198,\n",
       " ':]': 199,\n",
       " 'inconvienent': 200,\n",
       " 'had': 201,\n",
       " 'straight': 202,\n",
       " 'functionally': 203,\n",
       " 'landed': 204,\n",
       " 'ownership': 205,\n",
       " 'single': 206,\n",
       " 'external': 207,\n",
       " 'tiny': 208,\n",
       " 'win': 209,\n",
       " 'configure': 210,\n",
       " 'development': 211,\n",
       " '\"fast\"': 212,\n",
       " 'blue': 213,\n",
       " 'terms': 214,\n",
       " 'debate': 215,\n",
       " 'mcaffe': 216,\n",
       " 'please': 217,\n",
       " 'lame': 218,\n",
       " 'kit': 219,\n",
       " '$1199': 220,\n",
       " 'firewall/security': 221,\n",
       " 'price-point': 222,\n",
       " 'inconvenience': 223,\n",
       " 'hewitt': 224,\n",
       " 'borrow': 225,\n",
       " 'scratches': 226,\n",
       " 'durability': 227,\n",
       " 'favorite': 228,\n",
       " 'connected': 229,\n",
       " 'against': 230,\n",
       " 'unload': 231,\n",
       " 'anti-virus': 232,\n",
       " 'stellar': 233,\n",
       " 'wife': 234,\n",
       " 'warning': 235,\n",
       " 'history': 236,\n",
       " 'mc373ll/a': 237,\n",
       " 'nor': 238,\n",
       " 'tightened': 239,\n",
       " 'gone': 240,\n",
       " 'least': 241,\n",
       " 'occassionaly': 242,\n",
       " 'feb': 243,\n",
       " \"netbook's\": 244,\n",
       " 'clause': 245,\n",
       " '75%': 246,\n",
       " 'omitted': 247,\n",
       " 'normally': 248,\n",
       " 'malfunction': 249,\n",
       " 'planned': 250,\n",
       " 'discusion': 251,\n",
       " '998': 252,\n",
       " 'devoted': 253,\n",
       " 'assignments': 254,\n",
       " 'browsers': 255,\n",
       " 'chrome': 256,\n",
       " 'splurged': 257,\n",
       " 'explore': 258,\n",
       " 'proud': 259,\n",
       " 'wi-fi': 260,\n",
       " 'lump': 261,\n",
       " 'share': 262,\n",
       " 'device': 263,\n",
       " 'sales': 264,\n",
       " 'figure': 265,\n",
       " 'lbs': 266,\n",
       " 'agreed': 267,\n",
       " 'icons': 268,\n",
       " '$650': 269,\n",
       " 'case': 270,\n",
       " '*2': 271,\n",
       " 'occasional': 272,\n",
       " 'slots': 273,\n",
       " 'greater': 274,\n",
       " 'resetting': 275,\n",
       " 'defeats': 276,\n",
       " '\"human': 277,\n",
       " 'seal': 278,\n",
       " 'nb205': 279,\n",
       " 'main': 280,\n",
       " 'sharpness': 281,\n",
       " 'macminis': 282,\n",
       " 'aside': 283,\n",
       " 'flickr': 284,\n",
       " 'comparable': 285,\n",
       " 'gross': 286,\n",
       " 'however;': 287,\n",
       " 'hopefully': 288,\n",
       " 'teachers': 289,\n",
       " 'grabed': 290,\n",
       " 'superdrive': 291,\n",
       " 'let': 292,\n",
       " 'ahead': 293,\n",
       " 'promised': 294,\n",
       " '\"policies\"': 295,\n",
       " 'quietest': 296,\n",
       " 'doe': 297,\n",
       " 'underside': 298,\n",
       " 'screens': 299,\n",
       " 'for': 300,\n",
       " 'headsets': 301,\n",
       " 'phonecalls': 302,\n",
       " '2200': 303,\n",
       " 'similarly': 304,\n",
       " '3g': 305,\n",
       " 'beginner': 306,\n",
       " 'headphone': 307,\n",
       " 'startup': 308,\n",
       " 'discovered': 309,\n",
       " 'policy': 310,\n",
       " 'good:so': 311,\n",
       " 'preciously': 312,\n",
       " 'rarely': 313,\n",
       " 'noticably': 314,\n",
       " 'gb': 315,\n",
       " 'digitus': 316,\n",
       " 'books': 317,\n",
       " '53': 318,\n",
       " 'excelent': 319,\n",
       " '$99': 320,\n",
       " 'intalling': 321,\n",
       " 'asked': 322,\n",
       " 'switched': 323,\n",
       " 'wanna': 324,\n",
       " 'photoshop': 325,\n",
       " 'arrive': 326,\n",
       " '3dmark6': 327,\n",
       " 'eliminates': 328,\n",
       " 'lagging': 329,\n",
       " 'refurbished': 330,\n",
       " 'similarly-configured': 331,\n",
       " 'sealed': 332,\n",
       " 'compare': 333,\n",
       " 'curve': 334,\n",
       " 'all-in-all': 335,\n",
       " 'core': 336,\n",
       " 'glass': 337,\n",
       " 'last': 338,\n",
       " 'shells': 339,\n",
       " 'few': 340,\n",
       " 'comp': 341,\n",
       " 'san': 342,\n",
       " 'pc;': 343,\n",
       " 'professional': 344,\n",
       " 'definatly': 345,\n",
       " \"ol'\": 346,\n",
       " 'see': 347,\n",
       " 'randomly': 348,\n",
       " 'macosx': 349,\n",
       " 'uncommon': 350,\n",
       " 'plus': 351,\n",
       " 'processer': 352,\n",
       " \"dvd'd\": 353,\n",
       " 'heart': 354,\n",
       " 'log': 355,\n",
       " 'young': 356,\n",
       " 'cut': 357,\n",
       " '#': 358,\n",
       " 'opened': 359,\n",
       " 'crawl': 360,\n",
       " 'eyes': 361,\n",
       " 'security-prone': 362,\n",
       " 'connects': 363,\n",
       " 'imovie': 364,\n",
       " '\"mouse\"': 365,\n",
       " 'specific': 366,\n",
       " 'constandly': 367,\n",
       " 'weight': 368,\n",
       " 'seagate': 369,\n",
       " 'scores': 370,\n",
       " 'old': 371,\n",
       " 'occasions': 372,\n",
       " 'avoid': 373,\n",
       " 'surpassed': 374,\n",
       " 'minus': 375,\n",
       " 'printer': 376,\n",
       " 'simultaneously': 377,\n",
       " 'parallels': 378,\n",
       " \"you're\": 379,\n",
       " 'aftermarket': 380,\n",
       " 'mainly': 381,\n",
       " '[$]': 382,\n",
       " 'unique': 383,\n",
       " 'intel': 384,\n",
       " 'box': 385,\n",
       " 'sporting': 386,\n",
       " 'machine': 387,\n",
       " 'ordered': 388,\n",
       " 'read/write': 389,\n",
       " 'thank': 390,\n",
       " 'calling': 391,\n",
       " 'quits': 392,\n",
       " 'frills': 393,\n",
       " 'management': 394,\n",
       " 'performs': 395,\n",
       " 'adjustments': 396,\n",
       " '40': 397,\n",
       " '[': 398,\n",
       " 'keys': 399,\n",
       " 'important': 400,\n",
       " 'all': 401,\n",
       " 'promptly': 402,\n",
       " 'bein': 403,\n",
       " 'angles': 404,\n",
       " 'definitly': 405,\n",
       " 'show': 406,\n",
       " '$900+': 407,\n",
       " 'ways': 408,\n",
       " 'suite': 409,\n",
       " 'campus': 410,\n",
       " '00': 411,\n",
       " 'feeling': 412,\n",
       " 'laggy': 413,\n",
       " '2007': 414,\n",
       " 'crazy': 415,\n",
       " 'lackluster': 416,\n",
       " 'stolen': 417,\n",
       " 'suffice': 418,\n",
       " 'secured': 419,\n",
       " 'familiarize': 420,\n",
       " 'opposed': 421,\n",
       " 'thousands': 422,\n",
       " 'ex': 423,\n",
       " '@': 424,\n",
       " 'sensitive': 425,\n",
       " 'laser': 426,\n",
       " 'hardware': 427,\n",
       " 'missing': 428,\n",
       " 'total': 429,\n",
       " 'canon': 430,\n",
       " 'expectin': 431,\n",
       " 'lcd': 432,\n",
       " 'recordings': 433,\n",
       " 'lowan': 434,\n",
       " '\"fm\"': 435,\n",
       " '$36': 436,\n",
       " 'turing': 437,\n",
       " 'addict': 438,\n",
       " 'disappointments': 439,\n",
       " '1st': 440,\n",
       " 'current': 441,\n",
       " 'ridiculously': 442,\n",
       " 'funny': 443,\n",
       " \"acer's\": 444,\n",
       " 'standard': 445,\n",
       " 'stands': 446,\n",
       " 'reg': 447,\n",
       " 'company': 448,\n",
       " 'usps': 449,\n",
       " 'mountains': 450,\n",
       " '$799': 451,\n",
       " 'msn': 452,\n",
       " 'shift': 453,\n",
       " '\"max': 454,\n",
       " '200': 455,\n",
       " 'alot': 456,\n",
       " 'typically': 457,\n",
       " 'amazed': 458,\n",
       " 'outside': 459,\n",
       " 'past': 460,\n",
       " 'body': 461,\n",
       " 'silly': 462,\n",
       " '\"ivy': 463,\n",
       " 'brands': 464,\n",
       " 'remember': 465,\n",
       " 'grab': 466,\n",
       " 'beats': 467,\n",
       " 'anticipated': 468,\n",
       " '9ghz': 469,\n",
       " 'ecosystem': 470,\n",
       " 'set-up': 471,\n",
       " 'quess': 472,\n",
       " 'camper': 473,\n",
       " 'lion\"': 474,\n",
       " 'usual': 475,\n",
       " 'functional': 476,\n",
       " 'ya': 477,\n",
       " 'deployed': 478,\n",
       " 'meant': 479,\n",
       " 'welcomed': 480,\n",
       " 'monitor\"': 481,\n",
       " \"cd's\": 482,\n",
       " '$75': 483,\n",
       " 'disappointment': 484,\n",
       " 'advances': 485,\n",
       " 'iphoto': 486,\n",
       " 'older': 487,\n",
       " '$176': 488,\n",
       " 'dealing': 489,\n",
       " 'gui': 490,\n",
       " 'action': 491,\n",
       " 'semprom': 492,\n",
       " 'price': 493,\n",
       " 'temporary': 494,\n",
       " 'profile': 495,\n",
       " 'loving': 496,\n",
       " '16gb': 497,\n",
       " 'attached': 498,\n",
       " 'honest': 499,\n",
       " 'communicating': 500,\n",
       " 'networks': 501,\n",
       " 'continued': 502,\n",
       " '\"help\"': 503,\n",
       " 'nephews': 504,\n",
       " 'wants': 505,\n",
       " 'warcraft': 506,\n",
       " '\"junk\"': 507,\n",
       " 'unrelated': 508,\n",
       " 'items': 509,\n",
       " 'chances': 510,\n",
       " '\"abuse\"': 511,\n",
       " 'add': 512,\n",
       " 'mistaken': 513,\n",
       " 'front': 514,\n",
       " 'tells': 515,\n",
       " 'bloody': 516,\n",
       " 'diminish': 517,\n",
       " 'wiling': 518,\n",
       " 'interplanetary': 519,\n",
       " 'adversary': 520,\n",
       " '9': 521,\n",
       " 'arm': 522,\n",
       " 'extension': 523,\n",
       " 'utilize': 524,\n",
       " 'ran': 525,\n",
       " 'rating': 526,\n",
       " 'sentences': 527,\n",
       " 'logic': 528,\n",
       " 'reurn': 529,\n",
       " 'goodies': 530,\n",
       " 'hardly': 531,\n",
       " 'dog': 532,\n",
       " 'treat': 533,\n",
       " 'professed': 534,\n",
       " 'if': 535,\n",
       " 'child': 536,\n",
       " 'classroom': 537,\n",
       " 'customization': 538,\n",
       " 'relationship': 539,\n",
       " 'fix': 540,\n",
       " 'sd': 541,\n",
       " 'popular': 542,\n",
       " 'noticeable': 543,\n",
       " 'annoy': 544,\n",
       " 'avchd': 545,\n",
       " 'person': 546,\n",
       " 'reset': 547,\n",
       " 'moral': 548,\n",
       " '512mb': 549,\n",
       " 'peices': 550,\n",
       " 'clicks': 551,\n",
       " 'aluminium': 552,\n",
       " 'once': 553,\n",
       " 'walked': 554,\n",
       " 'possession': 555,\n",
       " 'emitting': 556,\n",
       " 'logon': 557,\n",
       " 'cheaper': 558,\n",
       " 'watt': 559,\n",
       " 'address': 560,\n",
       " 'anypne': 561,\n",
       " 'slot': 562,\n",
       " 'unexpectedly': 563,\n",
       " 'ton': 564,\n",
       " 'broken': 565,\n",
       " 'goodness-i': 566,\n",
       " 'happier': 567,\n",
       " 'going': 568,\n",
       " 'lemon\"': 569,\n",
       " 'photography': 570,\n",
       " 'premier': 571,\n",
       " 'initial': 572,\n",
       " 'furious': 573,\n",
       " 'uncomfortable': 574,\n",
       " 'dells': 575,\n",
       " 'dough': 576,\n",
       " 'was': 577,\n",
       " 'genius': 578,\n",
       " 'financing': 579,\n",
       " 'takes': 580,\n",
       " 'would': 581,\n",
       " 'pooch': 582,\n",
       " 'wal': 583,\n",
       " 'reduced': 584,\n",
       " 'tweezers': 585,\n",
       " 'notes': 586,\n",
       " 'immoble': 587,\n",
       " 'one\"': 588,\n",
       " 'speed': 589,\n",
       " 'drown': 590,\n",
       " 'fluid': 591,\n",
       " 'debates': 592,\n",
       " 'pounds': 593,\n",
       " 'fits': 594,\n",
       " 'returned': 595,\n",
       " 'below': 596,\n",
       " 'be:exceptionally': 597,\n",
       " 'exception': 598,\n",
       " 'robbery': 599,\n",
       " 'sp2': 600,\n",
       " 'sometimes': 601,\n",
       " '23': 602,\n",
       " 'cognitive': 603,\n",
       " \"'have\": 604,\n",
       " 'matched': 605,\n",
       " 'give': 606,\n",
       " 'definition': 607,\n",
       " 'change': 608,\n",
       " 'with-': 609,\n",
       " 'affecting': 610,\n",
       " 'isnt': 611,\n",
       " 'usability': 612,\n",
       " 'buyers': 613,\n",
       " 'acceptable': 614,\n",
       " 'tashiba': 615,\n",
       " 'self': 616,\n",
       " 'distan': 617,\n",
       " 'served': 618,\n",
       " 'awsome': 619,\n",
       " '-4': 620,\n",
       " 'increase': 621,\n",
       " 'direction': 622,\n",
       " 'sadly': 623,\n",
       " 'hafe': 624,\n",
       " 'forward': 625,\n",
       " 'anyone': 626,\n",
       " 'encounter': 627,\n",
       " 'babyed': 628,\n",
       " 'rants': 629,\n",
       " 'plug-in': 630,\n",
       " 'farther': 631,\n",
       " '1-to-1': 632,\n",
       " 'harder': 633,\n",
       " 'covering': 634,\n",
       " 'features:': 635,\n",
       " 'doubling': 636,\n",
       " 'qousmio': 637,\n",
       " 'coupla': 638,\n",
       " 'intalled': 639,\n",
       " 'household': 640,\n",
       " 'check': 641,\n",
       " 'decreased': 642,\n",
       " 'unfreeze': 643,\n",
       " \"y'all\": 644,\n",
       " 'figured': 645,\n",
       " 'quick': 646,\n",
       " 'this': 647,\n",
       " 'economical': 648,\n",
       " 'wont': 649,\n",
       " 'after': 650,\n",
       " 'mixed': 651,\n",
       " 'file': 652,\n",
       " 'respect': 653,\n",
       " 'necessary': 654,\n",
       " 'dabble': 655,\n",
       " 'preloaded': 656,\n",
       " 'existing': 657,\n",
       " 'confusing': 658,\n",
       " 'recovery': 659,\n",
       " 'blow': 660,\n",
       " 'knowledgeable': 661,\n",
       " 'helpful': 662,\n",
       " 'novice': 663,\n",
       " 'minutes': 664,\n",
       " 'backlit': 665,\n",
       " 'operation': 666,\n",
       " 'beauty': 667,\n",
       " 'anyones': 668,\n",
       " 'wheel': 669,\n",
       " 'defeated': 670,\n",
       " 'die': 671,\n",
       " 'reviews/surveys': 672,\n",
       " 'obscure': 673,\n",
       " 'deal--seemingly': 674,\n",
       " 'pcconnection': 675,\n",
       " 'disgusted': 676,\n",
       " 'warm': 677,\n",
       " 'knowlede': 678,\n",
       " 'handiecap': 679,\n",
       " 'definelty': 680,\n",
       " 'translates': 681,\n",
       " 'testing': 682,\n",
       " 'worth': 683,\n",
       " 'margin': 684,\n",
       " 'described': 685,\n",
       " 'email': 686,\n",
       " 'run': 687,\n",
       " 'events': 688,\n",
       " 'vpn': 689,\n",
       " 'safely': 690,\n",
       " 'sofa': 691,\n",
       " 'putting': 692,\n",
       " 'vice': 693,\n",
       " 'back-office': 694,\n",
       " 'use--': 695,\n",
       " 'cable': 696,\n",
       " 'pads': 697,\n",
       " 'buyer': 698,\n",
       " 'laptopwas': 699,\n",
       " 'acer': 700,\n",
       " 'adjusts': 701,\n",
       " 'nightmare': 702,\n",
       " 'investment': 703,\n",
       " 'tote': 704,\n",
       " 'secures': 705,\n",
       " 'came': 706,\n",
       " '75': 707,\n",
       " 'tutoring': 708,\n",
       " 'method': 709,\n",
       " 'noticable': 710,\n",
       " '$175': 711,\n",
       " 'keeps': 712,\n",
       " 'apart': 713,\n",
       " 'suggestions': 714,\n",
       " 'defect': 715,\n",
       " 'site': 716,\n",
       " 'disk': 717,\n",
       " 'grew': 718,\n",
       " '10-months': 719,\n",
       " 'flawlessly': 720,\n",
       " 'present': 721,\n",
       " 'superfine': 722,\n",
       " 'eee': 723,\n",
       " 'probbly': 724,\n",
       " 'darker': 725,\n",
       " 'production': 726,\n",
       " 'air': 727,\n",
       " 'kyle': 728,\n",
       " 'reaction': 729,\n",
       " 'known': 730,\n",
       " 'era': 731,\n",
       " 'intuition': 732,\n",
       " 'typers': 733,\n",
       " 'seperately': 734,\n",
       " '\"expedited\"': 735,\n",
       " 'mark': 736,\n",
       " 'common': 737,\n",
       " 'postage': 738,\n",
       " 'earn': 739,\n",
       " 'machouse': 740,\n",
       " 'outcome': 741,\n",
       " 'united': 742,\n",
       " 'robust': 743,\n",
       " 'replaced': 744,\n",
       " 'comfortably': 745,\n",
       " 'backlighting': 746,\n",
       " 'big': 747,\n",
       " 'great': 748,\n",
       " 'pride': 749,\n",
       " 'bedroom': 750,\n",
       " 'doesnt': 751,\n",
       " 'flash': 752,\n",
       " 'months': 753,\n",
       " 'balls': 754,\n",
       " '4g': 755,\n",
       " 'ipod': 756,\n",
       " 'catches': 757,\n",
       " 'scan': 758,\n",
       " '(': 759,\n",
       " 'before;': 760,\n",
       " 'glasses': 761,\n",
       " '-i': 762,\n",
       " 'transmissions': 763,\n",
       " 'reinstalled': 764,\n",
       " 'cae': 765,\n",
       " 'processing': 766,\n",
       " 'well-built': 767,\n",
       " 'incredible': 768,\n",
       " 'purposely': 769,\n",
       " 'prior': 770,\n",
       " 'promises': 771,\n",
       " 'it\"': 772,\n",
       " 'prolems': 773,\n",
       " 'minis': 774,\n",
       " 'licenses': 775,\n",
       " 'heading': 776,\n",
       " '65': 777,\n",
       " 'not': 778,\n",
       " 's': 779,\n",
       " 'queen': 780,\n",
       " 'considerably': 781,\n",
       " 'machine;': 782,\n",
       " 'paperwork': 783,\n",
       " '1000': 784,\n",
       " 'instructions': 785,\n",
       " 'refused': 786,\n",
       " 'position': 787,\n",
       " 'key': 788,\n",
       " 'droid': 789,\n",
       " 'cpu': 790,\n",
       " 'decline': 791,\n",
       " 'lacie': 792,\n",
       " 'reader': 793,\n",
       " 'does': 794,\n",
       " \"i've\": 795,\n",
       " 'weaknesses:a': 796,\n",
       " 'articles': 797,\n",
       " '10/10': 798,\n",
       " '0900': 799,\n",
       " \"you'll\": 800,\n",
       " 'codes': 801,\n",
       " 'mkii': 802,\n",
       " 'potentially': 803,\n",
       " 'look': 804,\n",
       " 'mother': 805,\n",
       " 'although': 806,\n",
       " 'toshiba-specific': 807,\n",
       " 'shot': 808,\n",
       " 'suck': 809,\n",
       " \"dosen't\": 810,\n",
       " 'niece': 811,\n",
       " \"weren't\": 812,\n",
       " 'is': 813,\n",
       " 'gave': 814,\n",
       " 'streaming': 815,\n",
       " ':-': 816,\n",
       " 'color': 817,\n",
       " 'sent': 818,\n",
       " 'access': 819,\n",
       " 'thigh': 820,\n",
       " 'country': 821,\n",
       " '\"hp/compaq\"': 822,\n",
       " 'easiest': 823,\n",
       " 'unmatched': 824,\n",
       " 'walking': 825,\n",
       " 'lloking': 826,\n",
       " 'satisfied': 827,\n",
       " 'sol': 828,\n",
       " 'spare': 829,\n",
       " 'kind': 830,\n",
       " 'goals': 831,\n",
       " 'move': 832,\n",
       " 'version': 833,\n",
       " '1500': 834,\n",
       " 'harddrives': 835,\n",
       " 'guessed': 836,\n",
       " 'sys': 837,\n",
       " 'shocked': 838,\n",
       " 'us': 839,\n",
       " 'problems': 840,\n",
       " 'unconcerned': 841,\n",
       " 'protected': 842,\n",
       " 'aluminum': 843,\n",
       " '.': 844,\n",
       " 'matters': 845,\n",
       " 'relevant': 846,\n",
       " 'dreamweaver': 847,\n",
       " 'movies': 848,\n",
       " 'sound': 849,\n",
       " 'xp': 850,\n",
       " 'wall': 851,\n",
       " 'faintly': 852,\n",
       " 'definite': 853,\n",
       " '6-7': 854,\n",
       " 'worrying': 855,\n",
       " 'charging\"': 856,\n",
       " 'critical': 857,\n",
       " 'it': 858,\n",
       " 'itthe': 859,\n",
       " 'support': 860,\n",
       " 'software': 861,\n",
       " 'gaming': 862,\n",
       " 'giant': 863,\n",
       " 'import': 864,\n",
       " 'bulky': 865,\n",
       " 'lived': 866,\n",
       " '>6': 867,\n",
       " 'l505-s5988': 868,\n",
       " 'sits': 869,\n",
       " 'loses': 870,\n",
       " 'imaging': 871,\n",
       " 'gibberish': 872,\n",
       " 'pavillion': 873,\n",
       " 'is:': 874,\n",
       " 'blog': 875,\n",
       " 'defrags': 876,\n",
       " '\"1764\"': 877,\n",
       " 'fumbling': 878,\n",
       " 'begining': 879,\n",
       " 'attempt': 880,\n",
       " 'unexpected': 881,\n",
       " 'exceeded': 882,\n",
       " 'non-functioning': 883,\n",
       " 'sheer': 884,\n",
       " 'non': 885,\n",
       " '\"net\"book': 886,\n",
       " 'shutdown': 887,\n",
       " 'pavilion': 888,\n",
       " 'button': 889,\n",
       " '25': 890,\n",
       " 'connect': 891,\n",
       " 'shop': 892,\n",
       " 'increases': 893,\n",
       " 'envy': 894,\n",
       " 'appealing': 895,\n",
       " 'were': 896,\n",
       " 'shipped': 897,\n",
       " 'shortening': 898,\n",
       " 'hunk': 899,\n",
       " 'trip': 900,\n",
       " 'idk': 901,\n",
       " 'nail': 902,\n",
       " 'defrag': 903,\n",
       " 'recharge': 904,\n",
       " 'from': 905,\n",
       " 'guess': 906,\n",
       " 'minimal': 907,\n",
       " 'low': 908,\n",
       " 'reasonably': 909,\n",
       " 'spend': 910,\n",
       " 'stupidly': 911,\n",
       " '-touchpad': 912,\n",
       " '$344': 913,\n",
       " 'rubber': 914,\n",
       " 'makes': 915,\n",
       " 'tons': 916,\n",
       " 'price/features': 917,\n",
       " 'retina': 918,\n",
       " 'ground': 919,\n",
       " 'movie': 920,\n",
       " 'noise': 921,\n",
       " 'yada-yada': 922,\n",
       " 'stated': 923,\n",
       " 'netbook:': 924,\n",
       " '\"cd': 925,\n",
       " 'temporarily': 926,\n",
       " 'fall': 927,\n",
       " '\"buy\"': 928,\n",
       " \"apple's\": 929,\n",
       " 'hair': 930,\n",
       " 'uses': 931,\n",
       " 'obviously': 932,\n",
       " 'whenever': 933,\n",
       " 'vlog': 934,\n",
       " 'making': 935,\n",
       " 'enjoyed': 936,\n",
       " 'grown': 937,\n",
       " 'core2': 938,\n",
       " 'bottom': 939,\n",
       " 'footprint': 940,\n",
       " 'lock': 941,\n",
       " 'occasion': 942,\n",
       " 'prompted': 943,\n",
       " '$3': 944,\n",
       " 'being': 945,\n",
       " 'ridiculous': 946,\n",
       " 'trouble': 947,\n",
       " 'question': 948,\n",
       " 'emachine': 949,\n",
       " 'head': 950,\n",
       " 'recall': 951,\n",
       " 'poorly': 952,\n",
       " 'seemlessly': 953,\n",
       " 'defects': 954,\n",
       " 'states': 955,\n",
       " '0': 956,\n",
       " 'rebooting': 957,\n",
       " 'stocks': 958,\n",
       " 'her': 959,\n",
       " 'stock': 960,\n",
       " 'flow': 961,\n",
       " 'results': 962,\n",
       " 'grafics': 963,\n",
       " 'abuse': 964,\n",
       " 'circle': 965,\n",
       " 'regretted': 966,\n",
       " '15-20': 967,\n",
       " 'sent:': 968,\n",
       " '\"top': 969,\n",
       " 'using': 970,\n",
       " 'drops': 971,\n",
       " 'accident': 972,\n",
       " 'asap': 973,\n",
       " 'saves': 974,\n",
       " 'logitech': 975,\n",
       " 'glitches': 976,\n",
       " 'insanity': 977,\n",
       " 'usable': 978,\n",
       " 'back': 979,\n",
       " 'usb3': 980,\n",
       " 'hrs': 981,\n",
       " 'garage': 982,\n",
       " 'waste': 983,\n",
       " 'said': 984,\n",
       " 'bios\"': 985,\n",
       " 'llast': 986,\n",
       " 'thunderbolt': 987,\n",
       " 'somewhere': 988,\n",
       " '18': 989,\n",
       " 'paid': 990,\n",
       " 'technician': 991,\n",
       " 'far': 992,\n",
       " 'fails': 993,\n",
       " 'constantly': 994,\n",
       " 'realizwed': 995,\n",
       " 'until': 996,\n",
       " 'behind': 997,\n",
       " 'powering': 998,\n",
       " 'weekends': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a mapping of words in vocab to index\n",
    "word2idx = {}\n",
    "word2idx['<UNK>'] = 0\n",
    "for i, word in enumerate(words):\n",
    "    word2idx[word] = i + 1\n",
    "\n",
    "n_words = len(word2idx)\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6eb15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a sentence class to get all the sentences\n",
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a3beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further format each sentence to the required format\n",
    "data = data_train\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences # get all sentences\n",
    "\n",
    "sent_tokens = [[w[0] for w in s] for s in sentences]\n",
    "sent_tags = [[w[1] for w in s] for s in sentences]\n",
    "training_data = list(zip(sent_tokens, sent_tags))\n",
    "\n",
    "getter_test = SentenceGetter(data_test)\n",
    "sentences_test = getter_test.sentences # get all sentences\n",
    "\n",
    "sent_tokens_test = [[w[0] for w in s] for s in sentences_test]\n",
    "sent_tags_test = [[w[1] for w in s] for s in sentences_test]\n",
    "testing_data = list(zip(sent_tokens_test, sent_tags_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79cd0b",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176ae716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pretrained glove embeds and extract relevant word vectors in vocab\n",
    "def get_glove_embeds():\n",
    "    glove_path = '../glove.840B.300d.txt'\n",
    "    embeddings_index = {}\n",
    "    with open(glove_path, encoding='utf8') as f:\n",
    "        for i, line in tqdm(enumerate(f)):\n",
    "            values = line.split()\n",
    "            word = ''.join(values[:-300])\n",
    "            coefs = np.asarray(values[-300:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    EMBEDDING_DIM = 300\n",
    "    embedding_matrix = np.zeros((len(words)+1, EMBEDDING_DIM))\n",
    "\n",
    "    for word, i in word2idx.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None:\n",
    "            embedding_matrix[i] = embeddings_index['unk']\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    embedding_matrix = torch.from_numpy(embedding_matrix).float()\n",
    "    return embedding_matrix, embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f7fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the skipgram and training of skipgram \n",
    "# Reference Prof Chris Lecture 6 Lecture Notebook\n",
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.V = nn.Embedding(vocab_size, embed_dim, max_norm=1)\n",
    "        self.U = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, centers):\n",
    "        out = self.V(centers)\n",
    "        out = self.U(out)\n",
    "        #out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "def get_skipgram_embeds():\n",
    "    \n",
    "    spacy.prefer_gpu()\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    all_tokens = sent_tokens + sent_tokens_test\n",
    "    tokens = [item for sublist in all_tokens for item in sublist]\n",
    "    #print(len(tokens))\n",
    "    window_size = 3\n",
    "\n",
    "    # Given the window size, we can directly infer the required sizes for the 2 Numpy arrays\n",
    "    skipgram = np.zeros(((len(tokens)-(2*window_size))*(2*window_size), 2), dtype=np.int32)\n",
    "\n",
    "    # Loop through list of tokens\n",
    "    for center_idx, pos in enumerate(range(window_size, len(tokens)-window_size)):\n",
    "\n",
    "        # Get current center word and current context words\n",
    "        center = tokens[pos]\n",
    "        context = tokens[pos-window_size:pos] + tokens[pos+1:pos+window_size+1]\n",
    "\n",
    "        # Loop over all context words to generate the 2*window_size (center_word, context_word)-pairs\n",
    "        for idx, c in enumerate(context):\n",
    "            skipgram_sample = np.array([  word2idx[center] if center in word2idx else 0 ,  word2idx[c] if c in word2idx else 0 ])\n",
    "            skipgram[(center_idx*window_size*2)+idx] = skipgram_sample\n",
    "    \n",
    "    data = skipgram\n",
    "    data = data.astype('int32')\n",
    "    num_samples, num_indices = data.shape\n",
    "    #print('Number of samples: {}'.format(num_samples))\n",
    "    vocab_size = len(word2idx)\n",
    "    \n",
    "    X = torch.Tensor(data[:,0]).long()\n",
    "    y = torch.Tensor(data[:,-1]).long()\n",
    "    \n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "    use_cuda = True\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    embed_dim = 300\n",
    "\n",
    "    model_skipgram = Skipgram(vocab_size, embed_dim)\n",
    "\n",
    "    # Move th model to GPU, if available (by default it \"stays\" on the CPU)\n",
    "    model_skipgram.to(device)\n",
    "    \n",
    "    num_epochs = 20\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_skipgram.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for idx, (x, y) in enumerate((dataloader)):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model_skipgram(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            model_skipgram.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print('Epoch: {}: Loss: {} '.format(epoch,epoch_loss))\n",
    "    \n",
    "    embedding_matrix = model_skipgram.U.weight\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98fe1ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [03:00, 12188.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011\n",
      "4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read glove or skipgram word embeddings\n",
    "if Embedding_feature == 'GLOVE':\n",
    "    embedding_matrix, embeddings_index = get_glove_embeds()\n",
    "elif Embedding_feature == 'Skipgram':\n",
    "    embedding_matrix = get_skipgram_embeds()\n",
    "\n",
    "if Embedding_feature == 'GLOVE':\n",
    "    word_true = 0\n",
    "    for word in words:\n",
    "        if word in embeddings_index:\n",
    "            word_true += 1\n",
    "\n",
    "    print(len(words))\n",
    "    print(word_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629739fc",
   "metadata": {},
   "source": [
    "### Process POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "646f8e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\zhida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'JJ'), ('charge', 'NN'), ('it', 'PRP'), ('at', 'IN'), ('night', 'NN'), ('and', 'CC'), ('skip', 'NN'), ('taking', 'VBG'), ('the', 'DT'), ('cord', 'NN'), ('with', 'IN'), ('me', 'PRP'), ('because', 'IN'), ('of', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('battery', 'NN'), ('life', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#use nltk to retrieve each sentence POS tags\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "tokenized_sentences = []\n",
    "tagged_sentences = []\n",
    "\n",
    "sentList = [x[0] for x in training_data] +  [x[0] for x in testing_data]\n",
    "\n",
    "for sentence in sentList:\n",
    "    tagged_sentence = nltk.pos_tag(sentence)\n",
    "    tagged_sentences.append(tagged_sentence)\n",
    "    \n",
    "print(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21dfcfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WDT', 'VBD', ',', 'FW', 'JJS', 'JJR', 'RP', 'JJ', 'VB', 'CD', 'VBG', '(', 'UH', 'POS', 'RBR', '.', 'IN', 'VBZ', 'LS', 'MD', 'VBN', 'RBS', \"''\", 'SYM', 'PRP$', 'VBP', ')', 'DT', 'NNS', 'EX', 'PRP', 'PDT', '#', 'WRB', 'NN', 'WP', 'NNP', ':', '$', 'TO', 'CC', 'RB']\n"
     ]
    }
   ],
   "source": [
    "#get all possible POS tags in vocab\n",
    "POS_sent_tags = [[w[1] for w in s] for s in tagged_sentences]\n",
    "POS_list_set = set().union(*POS_sent_tags)\n",
    "all_POS_tags = (list(POS_list_set))\n",
    "\n",
    "print(all_POS_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5dbc2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "{'WDT': 0, 'VBD': 1, ',': 0, 'FW': 2, 'JJS': 3, 'JJR': 4, 'RP': 5, 'JJ': 6, 'VB': 7, 'CD': 8, 'VBG': 9, '(': 0, 'UH': 10, 'POS': 11, 'RBR': 12, '.': 0, 'IN': 13, 'VBZ': 14, 'LS': 15, 'MD': 16, 'VBN': 17, 'RBS': 18, \"''\": 19, 'SYM': 20, 'PRP$': 21, 'VBP': 22, ')': 0, 'DT': 23, 'NNS': 24, 'EX': 25, 'PRP': 26, 'PDT': 27, '#': 0, 'WRB': 28, 'NN': 29, 'WP': 30, 'NNP': 31, ':': 0, '$': 0, 'TO': 32, 'CC': 33, 'RB': 34}\n"
     ]
    }
   ],
   "source": [
    "#create a mapping for POS and index\n",
    "POS2idx = {}\n",
    "counter = 0\n",
    "punctuation_str = '!\"#$%&\\'()*+, -./:;<=>?@[\\\\]^_`{|}~'\n",
    "for i, tag in enumerate(all_POS_tags):\n",
    "    if tag in punctuation_str:\n",
    "        POS2idx[tag] = 0\n",
    "    else:\n",
    "        POS2idx[tag] = counter\n",
    "        counter +=1\n",
    "\n",
    "num_POS_tags = counter\n",
    "print(num_POS_tags)\n",
    "print(POS2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474eb236",
   "metadata": {},
   "source": [
    "### Defining BiLSTM-CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebcd7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section define the BiLSTM_CRF model\n",
    "#References - PyTorch documenation and PyTorch Tutorial https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    #print(seq)\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, embedding_matrix, Embedding_feature, POS_feature, num_POS_tags, POS_hidden_dim, device):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.word_embeds = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "        assert self.word_embeds.weight.shape == embedding_matrix.shape\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        \n",
    "        #POS embedding and LSTM\n",
    "        pos_vocab_size = num_POS_tags\n",
    "        pos_embedding_dim = 10\n",
    "        pos_lstm_hidden_dim = POS_hidden_dim\n",
    "        self.pos_hidden_dim = pos_lstm_hidden_dim\n",
    "        self.pos_embeds = nn.Embedding(pos_vocab_size, pos_embedding_dim)\n",
    "        self.pos_lstm = nn.LSTM(pos_embedding_dim, pos_lstm_hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        if POS_feature == 'Yes':\n",
    "            self.hidden2tag = nn.Linear(hidden_dim+pos_lstm_hidden_dim, self.tagset_size)\n",
    "        else:\n",
    "            self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.pos_hidden = self.init_pos_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2,device=device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2,device=device))\n",
    "    \n",
    "    def init_pos_hidden(self):\n",
    "        return (torch.randn(2, 1, self.pos_hidden_dim // 2,device=device),\n",
    "                torch.randn(2, 1, self.pos_hidden_dim // 2,device=device))\n",
    "    \n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.,device=device)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence, pos_seq):\n",
    "        #for sentence\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        \n",
    "        #for pos\n",
    "        self.pos_hidden = self.init_pos_hidden()\n",
    "        pos_embeds = self.pos_embeds(pos_seq).view(len(pos_seq), 1, -1)\n",
    "        pos_lstm_out, self.pos_hidden = self.pos_lstm(pos_embeds, self.pos_hidden)\n",
    "        pos_lstm_out = pos_lstm_out.view(len(pos_seq), self.pos_hidden_dim)\n",
    "        \n",
    "        if POS_feature == 'Yes':\n",
    "            combined_lstm_out = torch.cat((lstm_out,pos_lstm_out),1)\n",
    "        else:\n",
    "            combined_lstm_out = lstm_out\n",
    "    \n",
    "        lstm_feats = self.hidden2tag(combined_lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1,device=device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.,device=device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags, pos_seq):\n",
    "\n",
    "        feats = self._get_lstm_features(sentence, pos_seq)\n",
    "\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        \n",
    "        score, tag_seq = self._viterbi_decode(feats)\n",
    "        \n",
    "        return forward_score - gold_score, tag_seq\n",
    "\n",
    "    def forward(self, sentence, pos_seq): \n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence, pos_seq)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2ee8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0df59376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7911e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function return all the aspect terms in the sentence based on the corresponding BIO tags\n",
    "def get_aspect(sentence,tags):\n",
    "    #sentence: list of tokens / words\n",
    "    #tags: 0-Beginning, 1-Inside, 2-Outside\n",
    "    #sentence = ['but', 'the', 'staff', 'was', 'so', 'horrible', 'to', 'us', '.']\n",
    "    #tags = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "    aspects = []\n",
    "    aspect = ''\n",
    "    #print('sentence',sentence)\n",
    "    #print('len',len(sentence))\n",
    "    for i in range(len(sentence)):\n",
    "        #print(i)\n",
    "        if tags[i] == 0:\n",
    "            if i>1:\n",
    "                if tags[i-1] == 1 or tags[i-1] == 0:\n",
    "                    aspect = aspect.lstrip(' ')\n",
    "                    aspects.append(aspect)\n",
    "                    aspect = ''\n",
    "            aspect = sentence[i]\n",
    "        elif tags[i] == 1:\n",
    "            aspect = aspect+' '+sentence[i]\n",
    "        elif tags[i] == 2:\n",
    "            if i>0:\n",
    "                if tags[i-1] == 1 or tags[i-1] == 0:\n",
    "                    aspect = aspect.lstrip(' ')\n",
    "                    aspects.append(aspect)\n",
    "                    aspect = ''\n",
    "        if i == len(sentence)-1 and aspect != '':\n",
    "            aspects.append(aspect)\n",
    "            aspect = ''\n",
    "    \n",
    "    #print(aspects)\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61056f",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f28c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to compute F1 score\n",
    "def F1score(pred_aspectTerms, gold_aspectTerms):\n",
    "    True_positives = 0\n",
    "    num_predictions = 0\n",
    "    num_gold = 0\n",
    "    for i in range(len(pred_aspectTerms)):\n",
    "        preds = pred_aspectTerms[i]\n",
    "        num_predictions += len(preds)\n",
    "        golds = gold_aspectTerms[i].copy()\n",
    "        num_gold += len(golds)\n",
    "        for j in range(len(preds)):\n",
    "            if preds[j] in golds:\n",
    "                True_positives += 1\n",
    "                golds.remove(preds[j])\n",
    "    if True_positives == 0:\n",
    "        return 0\n",
    "    precision = True_positives / num_predictions\n",
    "    recall = True_positives / num_gold\n",
    "    \n",
    "    return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "094e2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to train the model based on the optimiser and max num epochs\n",
    "#F1 score and accuracy are output for each epoch\n",
    "def train_model(model, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_epoch = -1\n",
    "    results = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            pred_aspectTerms = [] \n",
    "            gold_aspectTerms = []\n",
    "\n",
    "            if phase == 'train':\n",
    "                data = training_data\n",
    "            else:\n",
    "                data = testing_data\n",
    "                \n",
    "            # Iterate over data.\n",
    "            i = 0\n",
    "            for sentence, tags in (data):\n",
    "                sentence_in = prepare_sequence(sentence, word2idx).to(device)\n",
    "                targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long).to(device)\n",
    "                pos_seq = prepare_sequence(list(zip(*nltk.pos_tag(sentence)))[1],POS2idx).to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    loss, pred_tag = model.neg_log_likelihood(sentence_in, targets, pos_seq)\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                ground_truth_tags = torch.tensor([tag_to_ix[t] for t in data[i][1]], dtype=torch.long)\n",
    "                running_loss += loss.item()\n",
    "                if ground_truth_tags.tolist() == pred_tag:\n",
    "                    running_corrects += 1\n",
    "                i += 1\n",
    "                predicted_aspects_term = get_aspect(sentence,pred_tag)\n",
    "                ground_truth_aspects_term = get_aspect(sentence,ground_truth_tags.tolist())\n",
    "                pred_aspectTerms.append(predicted_aspects_term)\n",
    "                gold_aspectTerms.append(ground_truth_aspects_term)\n",
    "                #print('pred',pred_aspectTerms)\n",
    "                #print('gold',gold_aspectTerms)\n",
    "                \n",
    "            epoch_loss = running_loss / len(data)\n",
    "            epoch_acc = running_corrects/ len(data)\n",
    "            epoch_f1 = F1score(pred_aspectTerms,gold_aspectTerms)\n",
    "\n",
    "            print('{} Loss: {:.4f} F1: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_f1, epoch_acc))\n",
    "            result = [phase, epoch_loss, epoch_f1, epoch_acc]\n",
    "            results.append(result)\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_f1 = epoch_f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "                \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best f1 score: {best_f1:4f}')\n",
    "    print(f'Best epoch: {best_epoch}')\n",
    "    df = pd.DataFrame(results, columns = ['Phase', 'Loss','F1','Acc'])\n",
    "    filename = './'+Dataset_domain+'_Embed_'+Embedding_feature+'_POS_'+POS_feature+'_POSdim_'+str(POS_hidden_dim)+'.csv'\n",
    "    df.to_csv(filename) \n",
    "    \n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73f8d097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 2.1511 F1: 0.4627 Acc: 0.6201\n",
      "val Loss: 2.1069 F1: 0.3963 Acc: 0.5750\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.3304 F1: 0.6617 Acc: 0.7083\n",
      "val Loss: 1.7792 F1: 0.5354 Acc: 0.6388\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.1474 F1: 0.7059 Acc: 0.7411\n",
      "val Loss: 1.6977 F1: 0.5670 Acc: 0.6538\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.0424 F1: 0.7333 Acc: 0.7572\n",
      "val Loss: 1.6469 F1: 0.5962 Acc: 0.6737\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.9635 F1: 0.7507 Acc: 0.7680\n",
      "val Loss: 1.5959 F1: 0.6097 Acc: 0.6700\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.8902 F1: 0.7758 Acc: 0.7874\n",
      "val Loss: 1.4931 F1: 0.6392 Acc: 0.6963\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.8157 F1: 0.7915 Acc: 0.8005\n",
      "val Loss: 1.4424 F1: 0.6574 Acc: 0.7050\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.7600 F1: 0.8087 Acc: 0.8150\n",
      "val Loss: 1.3620 F1: 0.6895 Acc: 0.7338\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.7064 F1: 0.8275 Acc: 0.8301\n",
      "val Loss: 1.3547 F1: 0.6894 Acc: 0.7300\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.6491 F1: 0.8391 Acc: 0.8409\n",
      "val Loss: 1.4184 F1: 0.6895 Acc: 0.7312\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.6087 F1: 0.8436 Acc: 0.8451\n",
      "val Loss: 1.3993 F1: 0.6947 Acc: 0.7288\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.5413 F1: 0.8587 Acc: 0.8589\n",
      "val Loss: 1.6013 F1: 0.6637 Acc: 0.7163\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.5109 F1: 0.8709 Acc: 0.8698\n",
      "val Loss: 1.5110 F1: 0.6796 Acc: 0.7225\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.4681 F1: 0.8825 Acc: 0.8829\n",
      "val Loss: 1.5790 F1: 0.6891 Acc: 0.7338\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.4209 F1: 0.8910 Acc: 0.8894\n",
      "val Loss: 1.6194 F1: 0.6736 Acc: 0.7200\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3644 F1: 0.9072 Acc: 0.9062\n",
      "val Loss: 1.6696 F1: 0.6777 Acc: 0.7325\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3238 F1: 0.9130 Acc: 0.9121\n",
      "val Loss: 1.7729 F1: 0.6707 Acc: 0.7300\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.2965 F1: 0.9230 Acc: 0.9203\n",
      "val Loss: 1.8111 F1: 0.6807 Acc: 0.7312\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.2525 F1: 0.9381 Acc: 0.9341\n",
      "val Loss: 1.6893 F1: 0.7045 Acc: 0.7475\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.2127 F1: 0.9481 Acc: 0.9413\n",
      "val Loss: 1.8101 F1: 0.7013 Acc: 0.7388\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.1991 F1: 0.9514 Acc: 0.9462\n",
      "val Loss: 2.1516 F1: 0.6626 Acc: 0.7262\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.1859 F1: 0.9554 Acc: 0.9472\n",
      "val Loss: 2.0182 F1: 0.6879 Acc: 0.7300\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.1632 F1: 0.9614 Acc: 0.9541\n",
      "val Loss: 2.0962 F1: 0.6706 Acc: 0.7212\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.1296 F1: 0.9744 Acc: 0.9669\n",
      "val Loss: 2.0571 F1: 0.7031 Acc: 0.7388\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.1175 F1: 0.9741 Acc: 0.9682\n",
      "val Loss: 2.2932 F1: 0.6983 Acc: 0.7425\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.1078 F1: 0.9788 Acc: 0.9738\n",
      "val Loss: 2.2488 F1: 0.7057 Acc: 0.7488\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.1231 F1: 0.9704 Acc: 0.9633\n",
      "val Loss: 2.1468 F1: 0.7117 Acc: 0.7550\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.1068 F1: 0.9757 Acc: 0.9698\n",
      "val Loss: 2.3761 F1: 0.6995 Acc: 0.7425\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0906 F1: 0.9797 Acc: 0.9770\n",
      "val Loss: 2.2902 F1: 0.7108 Acc: 0.7462\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0730 F1: 0.9875 Acc: 0.9829\n",
      "val Loss: 2.2652 F1: 0.7163 Acc: 0.7550\n",
      "\n",
      "Training complete in 130m 45s\n",
      "Best f1 score: 0.716318\n",
      "Best epoch: 29\n"
     ]
    }
   ],
   "source": [
    "#define model, optimiser and execute training\n",
    "model = BiLSTM_CRF(len(word2idx), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, embedding_matrix, Embedding_feature, POS_feature, num_POS_tags, POS_hidden_dim, device).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4) \n",
    "num_epochs = 30\n",
    "model = train_model(model, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecfa54d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "#save the model that yield best result\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "torch.save(model.state_dict(), os.path.join(ROOT_DIR, 'parameters.pt'))\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403802e4",
   "metadata": {},
   "source": [
    "### Evaluate Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65a34b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results for the test set for further error analysis\n",
    "s = []\n",
    "gt = []\n",
    "pred = []\n",
    "data_save = []\n",
    "\n",
    "for i in range(len(testing_data)):\n",
    "    \n",
    "    sentence = testing_data[i][0]\n",
    "    tags = testing_data[i][1]\n",
    "    \n",
    "    sentence_in = prepare_sequence(sentence, word2idx).to(device)\n",
    "    targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long).to(device)\n",
    "    pos_seq = prepare_sequence(list(zip(*nltk.pos_tag(sentence)))[1],POS2idx).to(device)\n",
    "    loss, pred_tag = model.neg_log_likelihood(sentence_in, targets, pos_seq)\n",
    "    ground_truth_tags = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "    predicted_aspects_term = get_aspect(sentence,pred_tag)\n",
    "    ground_truth_aspects_term = get_aspect(sentence,ground_truth_tags.tolist())\n",
    "    \n",
    "    data_save.append([sentence,ground_truth_aspects_term,predicted_aspects_term])\n",
    "    s.append(testing_data[i][1])\n",
    "    gt.append(ground_truth_aspects_term)\n",
    "    pred.append(predicted_aspects_term)\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(data_save, columns = ['sentence', 'ground_truth','pred'])\n",
    "df.to_csv('Laptop_NO_POS_test.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30789d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.7520325203252033\n",
      "0.6761768901569187\n"
     ]
    }
   ],
   "source": [
    "#Compare results based on different number of aspect terms in each review\n",
    "cat_a_gt = []\n",
    "cat_b_gt = []\n",
    "cat_c_gt = []\n",
    "cat_a_pred = []\n",
    "cat_b_pred = []\n",
    "cat_c_pred = []\n",
    "for i in range(len(s)):\n",
    "    if len(gt[i]) == 0: #if zero aspect term\n",
    "        cat_a_gt.append(gt[i])\n",
    "        cat_a_pred.append(pred[i])\n",
    "    elif len(gt[i]) == 1:  #if 1 aspect term\n",
    "        cat_b_gt.append(gt[i])\n",
    "        cat_b_pred.append(pred[i])\n",
    "    elif len(gt[i]) > 1: #if >1 aspect term\n",
    "        cat_c_gt.append(gt[i])\n",
    "        cat_c_pred.append(pred[i])\n",
    "print(F1score(cat_a_pred,cat_a_gt))\n",
    "print(F1score(cat_b_pred,cat_b_gt))\n",
    "print(F1score(cat_c_pred,cat_c_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e64099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6162624821683309\n",
      "0.8223552894211577\n"
     ]
    }
   ],
   "source": [
    "#Compare results based on if there are multi-word aspect terms in the review\n",
    "cat_a_gt = []\n",
    "cat_b_gt = []\n",
    "cat_a_pred = []\n",
    "cat_b_pred = []\n",
    "for i in range(len(s)):\n",
    "    if ' ' in ''.join(gt[i]):  #if consist multi-word aspect terms\n",
    "        cat_a_gt.append(gt[i])\n",
    "        cat_a_pred.append(pred[i])\n",
    "    else:\n",
    "        cat_b_gt.append(gt[i])\n",
    "        cat_b_pred.append(pred[i])\n",
    "print(F1score(cat_a_pred,cat_a_gt))\n",
    "print(F1score(cat_b_pred,cat_b_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc59db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ce7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
